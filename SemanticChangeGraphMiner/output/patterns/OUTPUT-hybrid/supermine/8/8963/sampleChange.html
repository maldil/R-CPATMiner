<link rel="stylesheet" href="../../../../default.css">
<script src="../../../../highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><h3></h3><h3>Before Change</h3><pre><code class='java'>
            languages=squeeze_1d(None),
        )
        &#47&#47 call model
        <a id="change">dense_feat = self.normalizer.normalize(dense_feat)</a>
        dense_tensor = <a id="change">torch.tensor(dense_feat, dtype=torch.float)</a>
        if self.tensorizer.device != "":
            dense_tensor = dense_tensor.to(self.tensorizer.device)

        sentence_embedding = self._forward(inputs, dense_tensor)
        if self.concat_dense:
            <a id="change">return torch.cat([sentence_embedding, dense_tensor], 1)</a>
        else:
            return sentence_embedding

    @torch.jit.script_method</code></pre><h3>After Change</h3><pre><code class='java'>

        result = self.forward_impl(texts[:max_batch], dense_feat[:max_batch])

        <a id="change">if input_len &gt; max_batch:
            texts = texts[max_batch:]
            dense_feat = dense_feat[max_batch:]

            while len(texts) &gt; 0:
                result_extension = self.forward_impl(
                    texts[:max_batch], dense_feat[:max_batch]
                )
                &#47&#47 the result of forward is either a torch.Tensor or a List[Any]
                if isinstance(result, torch.Tensor):
                    result = torch.cat([result, result_extension], dim=0)
                else:
                    result.extend(result_extension)

                texts = texts[max_batch:]
                dense_feat = dense_feat[max_batch:]

       </a> <a id="change">return result</a>

    @torch.jit.script_method
    def make_prediction(
        self,</code></pre>